{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fa1ace3-15ff-49e4-a2c6-79a8222dab44",
   "metadata": {},
   "source": [
    "Training file:\n",
    "===============\n",
    "\n",
    "Following is the code to do a basic check for the examples that we are passing. It will be checking if it is able to open and read the file and will also give the length of role messages we have included. In the below code I am giving around 20 examples and I believe the model has learnt enough information to respond properly to our prompts while inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ebd04b7-3603-423b-b197-57e98b55eb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic checks for file C:\\Users\\Riaz\\Desktop\\MSDS\\Generative AI\\Week 9\\milestone3.jsonl:\n",
      "Count of examples in training dataset: 20\n",
      "First example:\n",
      "{'role': 'system', 'content': 'You are a well-informed assistant. Provide responses based on fine-tuned data first. If the fine-tuned knowledge does not cover the query, use your general knowledge to provide a helpful answer.'}\n",
      "{'role': 'user', 'content': 'What are some common christian names'}\n",
      "{'role': 'assistant', 'content': 'Peter, James,Paul,Sander,Christine,Samuel,Joel,Barry,Jerry,Kat,Donald,Joseph,Mary,Perry,Lindsey,Carolina'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "def basic_checks(data_file):\n",
    "    try:\n",
    "        with open(data_file, 'r', encoding='utf-8') as f:\n",
    "            dataset = [json.loads(line) for line in f]\n",
    "        print(f\"Basic checks for file {data_file}:\")\n",
    "        print(\"Count of examples in training dataset:\", len(dataset))\n",
    "        print(\"First example:\")\n",
    "        for message in dataset[0][\"messages\"]:\n",
    "            print(message)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in file {data_file}: {e}\")\n",
    "        return False\n",
    "\n",
    "basic_checks(f'C:\\\\Users\\\\Riaz\\\\Desktop\\\\MSDS\\\\Generative AI\\\\Week 9\\\\milestone3.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc415455-62ab-4a05-826a-e7b1fbecdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import openai\n",
    "#import openai\n",
    "from openai import OpenAI\n",
    "openai.api_key =os.getenv(\"openai_api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb8b13-37dc-4317-9db7-3b3a5a3a7dd6",
   "metadata": {},
   "source": [
    "Training file upload:\n",
    "=====================\n",
    "\n",
    "The created file is being uploaded using the files API, this is required for the fine tuning job to pick the training file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1904d37d-2c14-4be5-85fe-5c20c1808d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The information of uploaded files\n",
      " SyncCursorPage[FileObject](data=[FileObject(id='file-6e5aQT23rRvnofNJBvrAAC', bytes=8051, created_at=1738963807, filename='milestone3.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-491rrrZdaxr6e34pTwGVQ6', bytes=7999, created_at=1738962949, filename='milestone3.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-N1ZnuG19XQiQxMy686xB87', bytes=7985, created_at=1738962521, filename='milestone3.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-Ey9L51DRxJAKnRm7AWMut5', bytes=2652, created_at=1737861594, filename='step_metrics.csv', object='file', purpose='fine-tune-results', status='processed', status_details=None), FileObject(id='file-FNdXMDgfG35syu5VTKvcft', bytes=2242, created_at=1737861110, filename='data_file', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-RffFCTQefajKoKMd7AaesC', bytes=2644, created_at=1737749530, filename='step_metrics.csv', object='file', purpose='fine-tune-results', status='processed', status_details=None), FileObject(id='file-GEJRrXbqseFqXxdUn6cF4Z', bytes=2242, created_at=1737749017, filename='data_file', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-J2jAiXJTExmrqfMVQ8fYeg', bytes=666, created_at=1737747122, filename='data_file', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-MFathCpeBf1sismJMxooHv', bytes=666, created_at=1737747089, filename='data_file', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-7vXLJiQf1Kb9A8MA8ZUs3U', bytes=666, created_at=1737746964, filename='data_file', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-TWuGDoyqcRCx9bQGe1gd3e', bytes=666, created_at=1737746944, filename='data_file', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-Qs2dWA63SNdCW7VrgK4FuV', bytes=666, created_at=1737746921, filename='data_file', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-7FBQoxRYhhHruJxfex9FBb', bytes=666, created_at=1737746902, filename='data_file', object='file', purpose='fine-tune', status='processed', status_details=None)], object='list', has_more=False, first_id='file-6e5aQT23rRvnofNJBvrAAC', last_id='file-7FBQoxRYhhHruJxfex9FBb')\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.files.create(\n",
    "  file=open(\"C:\\\\Users\\\\Riaz\\\\Desktop\\\\MSDS\\\\Generative AI\\\\Week 9\\\\milestone3.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print (\"The information of uploaded files\\n\",client.files.list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b388b9c-bd2e-44c9-86b0-ad6fc03210a7",
   "metadata": {},
   "source": [
    "Fine tuning job:\n",
    "================\n",
    "\n",
    "Fine tuning job needs to be created with the parameter of file id and this is retrieved from the above files.list api. The below command creates a finetuning job and the model gpt-4o-mini-2024-07-18 has been specified.\n",
    "The list of fine tunable models can be retrieved from https://platform.openai.com/docs/guides/fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "228d2073-eaac-477e-a7e9-e01f7f1be757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-Zood5bzNC0ABYOsKfRxzqv3b', created_at=1738962615, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-CICsZaJ3gjcM8Nb7O39cmoMG', result_files=[], seed=1459910765, status='validating_files', trained_tokens=None, training_file='file-N1ZnuG19XQiQxMy686xB87', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto')), type='supervised'), user_provided_suffix=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.fine_tuning.jobs.create(training_file=\"file-N1ZnuG19XQiQxMy686xB87\",model=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f74c1de6-02bc-4662-8cee-d135be4a901f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-SqCYGHxnWaB7saht4FKgh6tk', created_at=1738963823, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-CICsZaJ3gjcM8Nb7O39cmoMG', result_files=[], seed=2066327869, status='validating_files', trained_tokens=None, training_file='file-6e5aQT23rRvnofNJBvrAAC', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto')), type='supervised'), user_provided_suffix=None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.fine_tuning.jobs.create(training_file=\"file-6e5aQT23rRvnofNJBvrAAC\",model=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c34f4-3b65-4d90-98f8-449577e9aa07",
   "metadata": {},
   "source": [
    "Job information retrieval:\n",
    "==========================\n",
    "\n",
    "Following is the command to get the list of running jobs and to retrieve the job details.\n",
    "This is required, as it will give the fine tuned model.\n",
    "While we use the chat completions API to query the LLM, this fine tuned model needs to be specified.\n",
    "As we have not given the hyperparameters, it choses itself the optimimum values and displays the hyperparameters used like number of epochs, whether it is supervised or not and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "127f7e20-2daa-4b27-a419-732c69c9f2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-SqCYGHxnWaB7saht4FKgh6tk', created_at=1738963823, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2', finished_at=1738964175, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=5), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-CICsZaJ3gjcM8Nb7O39cmoMG', result_files=['file-QTfW1Uw1v5yQs1uQJ4GSgz'], seed=2066327869, status='succeeded', trained_tokens=7480, training_file='file-6e5aQT23rRvnofNJBvrAAC', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=5)), type='supervised'), user_provided_suffix=None)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list(limit=10)\n",
    "client.fine_tuning.jobs.retrieve('ftjob-SqCYGHxnWaB7saht4FKgh6tk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6111431-cd2a-4ba4-9430-ce856f2c7eb9",
   "metadata": {},
   "source": [
    "The job initially failed with error, \"The job failed due to an invalid training file. This training file was blocked by our moderation system because it contains too many examples that violate OpenAI's usage policies, or because it attempts to create model outputs that violate OpenAI's usage policies.\"\n",
    "\n",
    "What I have understood is, if we use words like \"hate\" or try to generalize any particular group or give some personal information about anyone, we cant train the model as the training file gets flagged.  It throws the above error, which is really interesting to note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "93114467-3190-4ece-9793-e3ab37b42c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-Zood5bzNC0ABYOsKfRxzqv3b', created_at=1738962615, error=Error(code='invalid_training_file', message=\"The job failed due to an invalid training file. This training file was blocked by our moderation system because it contains too many examples that violate OpenAI's usage policies, or because it attempts to create model outputs that violate OpenAI's usage policies.\", param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=5), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-CICsZaJ3gjcM8Nb7O39cmoMG', result_files=[], seed=1459910765, status='failed', trained_tokens=None, training_file='file-N1ZnuG19XQiQxMy686xB87', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=5)), type='supervised'), user_provided_suffix=None)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve('ftjob-Zood5bzNC0ABYOsKfRxzqv3b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1054b76-ddcf-42ac-bb50-de390a6462b0",
   "metadata": {},
   "source": [
    "Metrics retrieval:\n",
    "==================\n",
    "\n",
    "I am getting the metrics by using the appropriate APIs from the above result_files file which got generated after fine tuning job succeeded.\n",
    "This needs to be converted from base64 format to be human readable,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3f6fb289-be62-4cf8-a062-e3c8ef883eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'step,train_loss,train_accuracy,valid_loss,valid_mean_token_accuracy,train_mean_reward,full_validation_mean_reward\\n1,7.60396,0.44444,,,,\\n2,4.14012,0.31818,,,,\\n3,5.50628,0.34286,,,,\\n4,5.14447,0.4,,,,\\n5,4.9297,0.625,,,,\\n6,6.8558,0.55556,,,,\\n7,5.14884,0.5,,,,\\n8,3.81917,0.33333,,,,\\n9,6.19197,0.66667,,,,\\n10,4.64677,0.4,,,,\\n11,4.78113,0.45455,,,,\\n12,2.56068,0.38462,,,,\\n13,3.92422,0.35714,,,,\\n14,3.76372,0.35294,,,,\\n15,3.76925,0.36111,,,,\\n16,2.95576,0.4,,,,\\n17,2.57482,0.57143,,,,\\n18,2.03821,0.66667,,,,\\n19,1.88549,0.6,,,,\\n20,3.68693,0.33333,,,,\\n21,1.3662,0.7,,,,\\n22,2.77002,0.38636,,,,\\n23,1.2417,0.66667,,,,\\n24,1.90839,0.71429,,,,\\n25,1.69144,0.66667,,,,\\n26,3.45308,0.34286,,,,\\n27,1.15316,0.55556,,,,\\n28,0.89693,0.75,,,,\\n29,1.58748,0.66667,,,,\\n30,2.60766,0.52778,,,,\\n31,0.23619,1.0,,,,\\n32,2.51579,0.35294,,,,\\n33,2.89136,0.42857,,,,\\n34,2.00357,0.56,,,,\\n35,1.46842,0.53333,,,,\\n36,2.08829,0.61538,,,,\\n37,2.37207,0.53333,,,,\\n38,2.81988,0.33333,,,,\\n39,2.04664,0.6,,,,\\n40,2.56182,0.5,,,,\\n41,2.63767,0.42857,,,,\\n42,2.14897,0.4,,,,\\n43,0.82323,0.75,,,,\\n44,0.60678,0.77778,,,,\\n45,0.72008,0.73333,,,,\\n46,2.3075,0.43182,,,,\\n47,1.5353,0.68,,,,\\n48,0.44001,0.9,,,,\\n49,1.58172,0.53333,,,,\\n50,0.77262,0.66667,,,,\\n51,2.78129,0.4,,,,\\n52,0.43975,0.75,,,,\\n53,1.06581,0.69231,,,,\\n54,0.62541,0.83333,,,,\\n55,1.8784,0.58333,,,,\\n56,0.8838,0.6,,,,\\n57,1.76484,0.54545,,,,\\n58,0.02823,1.0,,,,\\n59,1.54647,0.64706,,,,\\n60,0.48306,0.85714,,,,\\n61,2.33979,0.51429,,,,\\n62,0.09164,1.0,,,,\\n63,0.76688,0.69231,,,,\\n64,1.10431,0.6,,,,\\n65,1.77093,0.54545,,,,\\n66,1.09075,0.76471,,,,\\n67,0.25238,1.0,,,,\\n68,1.07084,0.66667,,,,\\n69,0.1095,1.0,,,,\\n70,1.0938,0.81818,,,,\\n71,0.71128,0.8,,,,\\n72,0.09598,1.0,,,,\\n73,2.05421,0.52381,,,,\\n74,0.14287,1.0,,,,\\n75,0.37543,0.91667,,,,\\n76,1.39811,0.63889,,,,\\n77,0.00739,1.0,,,,\\n78,0.02874,1.0,,,,\\n79,0.32938,0.88889,,,,\\n80,0.44592,0.86667,,,,\\n81,0.30285,0.93333,,,,\\n82,0.00138,1.0,,,,\\n83,0.41839,0.92,,,,\\n84,0.77068,0.73333,,,,\\n85,1.33915,0.61364,,,,\\n86,0.00047,1.0,,,,\\n87,1.11033,0.75,,,,\\n88,0.74213,0.8,,,,\\n89,0.00605,1.0,,,,\\n90,0.08387,1.0,,,,\\n91,0.01171,1.0,,,,\\n92,1.6008,0.61905,,,,\\n93,0.03239,1.0,,,,\\n94,1.53054,0.62857,,,,\\n95,0.47078,0.82353,,,,\\n96,0.0874,0.88889,,,,\\n97,0.74018,0.81818,,,,\\n98,0.51458,0.76923,,,,\\n99,0.00693,1.0,,,,\\n100,0.41914,0.83333,,,,\\n'\n"
     ]
    }
   ],
   "source": [
    "file_id = \"file-QTfW1Uw1v5yQs1uQJ4GSgz\" \n",
    "\n",
    "# Retrieve file content\n",
    "file_content = client.files.content(file_id)\n",
    "\n",
    "# Read binary data and decode it properly\n",
    "decoded_content = file_content.read().decode(\"utf-8\")\n",
    "\n",
    "# Print first few lines for inspection\n",
    "import base64\n",
    "print (base64.b64decode(decoded_content)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ad448-87c8-4c31-a70d-e7ebe25cedd0",
   "metadata": {},
   "source": [
    "From https://www.base64decode.org/,\n",
    "\n",
    "step,train_loss,train_accuracy,valid_loss,valid_mean_token_accuracy,train_mean_reward,full_validation_mean_reward\n",
    "1,7.60396,0.44444,,,,\n",
    "2,4.14012,0.31818,,,,\n",
    "3,5.50628,0.34286,,,,\n",
    "4,5.14447,0.4,,,,\n",
    "5,4.9297,0.625,,,,\n",
    "6,6.8558,0.55556,,,,\n",
    "7,5.14884,0.5,,,,\n",
    "8,3.81917,0.33333,,,,\n",
    "9,6.19197,0.66667,,,,\n",
    "10,4.64677,0.4,,,,\n",
    "11,4.78113,0.45455,,,,\n",
    "12,2.56068,0.38462,,,,\n",
    "13,3.92422,0.35714,,,,\n",
    "14,3.76372,0.35294,,,,\n",
    "15,3.76925,0.36111,,,,\n",
    "16,2.95576,0.4,,,,\n",
    "17,2.57482,0.57143,,,,\n",
    "18,2.03821,0.66667,,,,\n",
    "19,1.88549,0.6,,,,\n",
    "20,3.68693,0.33333,,,,\n",
    "21,1.3662,0.7,,,,\n",
    "22,2.77002,0.38636,,,,\n",
    "23,1.2417,0.66667,,,,\n",
    "24,1.90839,0.71429,,,,\n",
    "25,1.69144,0.66667,,,,\n",
    "26,3.45308,0.34286,,,,\n",
    "27,1.15316,0.55556,,,,\n",
    "28,0.89693,0.75,,,,\n",
    "29,1.58748,0.66667,,,,\n",
    "30,2.60766,0.52778,,,,\n",
    "31,0.23619,1.0,,,,\n",
    "32,2.51579,0.35294,,,,\n",
    "33,2.89136,0.42857,,,,\n",
    "34,2.00357,0.56,,,,\n",
    "35,1.46842,0.53333,,,,\n",
    "36,2.08829,0.61538,,,,\n",
    "37,2.37207,0.53333,,,,\n",
    "38,2.81988,0.33333,,,,\n",
    "39,2.04664,0.6,,,,\n",
    "40,2.56182,0.5,,,,\n",
    "41,2.63767,0.42857,,,,\n",
    "42,2.14897,0.4,,,,\n",
    "43,0.82323,0.75,,,,\n",
    "44,0.60678,0.77778,,,,\n",
    "45,0.72008,0.73333,,,,\n",
    "46,2.3075,0.43182,,,,\n",
    "47,1.5353,0.68,,,,\n",
    "48,0.44001,0.9,,,,\n",
    "49,1.58172,0.53333,,,,\n",
    "50,0.77262,0.66667,,,,\n",
    "51,2.78129,0.4,,,,\n",
    "52,0.43975,0.75,,,,\n",
    "53,1.06581,0.69231,,,,\n",
    "54,0.62541,0.83333,,,,\n",
    "55,1.8784,0.58333,,,,\n",
    "56,0.8838,0.6,,,,\n",
    "57,1.76484,0.54545,,,,\n",
    "58,0.02823,1.0,,,,\n",
    "59,1.54647,0.64706,,,,\n",
    "60,0.48306,0.85714,,,,\n",
    "61,2.33979,0.51429,,,,\n",
    "62,0.09164,1.0,,,,\n",
    "63,0.76688,0.69231,,,,\n",
    "64,1.10431,0.6,,,,\n",
    "65,1.77093,0.54545,,,,\n",
    "66,1.09075,0.76471,,,,\n",
    "67,0.25238,1.0,,,,\n",
    "68,1.07084,0.66667,,,,\n",
    "69,0.1095,1.0,,,,\n",
    "70,1.0938,0.81818,,,,\n",
    "71,0.71128,0.8,,,,\n",
    "72,0.09598,1.0,,,,\n",
    "73,2.05421,0.52381,,,,\n",
    "74,0.14287,1.0,,,,\n",
    "75,0.37543,0.91667,,,,\n",
    "76,1.39811,0.63889,,,,\n",
    "77,0.00739,1.0,,,,\n",
    "78,0.02874,1.0,,,,\n",
    "79,0.32938,0.88889,,,,\n",
    "80,0.44592,0.86667,,,,\n",
    "81,0.30285,0.93333,,,,\n",
    "82,0.00138,1.0,,,,\n",
    "83,0.41839,0.92,,,,\n",
    "84,0.77068,0.73333,,,,\n",
    "85,1.33915,0.61364,,,,\n",
    "86,0.00047,1.0,,,,\n",
    "87,1.11033,0.75,,,,\n",
    "88,0.74213,0.8,,,,\n",
    "89,0.00605,1.0,,,,\n",
    "90,0.08387,1.0,,,,\n",
    "91,0.01171,1.0,,,,\n",
    "92,1.6008,0.61905,,,,\n",
    "93,0.03239,1.0,,,,\n",
    "94,1.53054,0.62857,,,,\n",
    "95,0.47078,0.82353,,,,\n",
    "96,0.0874,0.88889,,,,\n",
    "97,0.74018,0.81818,,,,\n",
    "98,0.51458,0.76923,,,,\n",
    "99,0.00693,1.0,,,,\n",
    "100,0.41914,0.83333,,,,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52599a-0068-4418-aaa4-6875a8b46c37",
   "metadata": {},
   "source": [
    "Metrics evaluation:\n",
    "===================\n",
    "\n",
    "From the above metrics information, we are seeing only the step,train_loss,train_accuracy has been populated.  The other options are not up there, as we have not used the validation file and they all correspond to the validation metrics.\n",
    "\n",
    "The default of 100 steps has been used here for training.\n",
    "\n",
    "About the training loss, the lesser the number it is good, it is the parameter which defines how much the predicted output from model differs from the expected output\n",
    "\n",
    "Initially high (7.60 at step 1), then decreases significantly over time.\n",
    "Final loss (step 100) is 0.41, indicating the model has learned well.\n",
    "\n",
    "About the training accuracy, the more it is good and it is expressed as percentage, it is the parameter which defines how accurately the model is predicting the next token.\n",
    "\n",
    "Starts at 0.444 (44.4%) at step 1.\n",
    "Final accuracy is 0.83 (83.33%) at step 100, meaning the model is making correct predictions most of the time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6382a11-210c-455b-90bd-a1aa112b8c86",
   "metadata": {},
   "source": [
    "Model inference:\n",
    "================\n",
    "\n",
    "Perplexity, accuracy of information and hallucination.\n",
    "\n",
    "Various prompts are made to test the quality of the trained model.\n",
    "\n",
    "Based on our training data, the following were the right responses given by the model,\n",
    "\n",
    "Meow machines can be gifted to cats and their owners. - Meow machine is given in the training data.\n",
    "Riaz prefers chillies as gifts\n",
    "Vijay might prefer traditional Indian gifts - Model was able to understand that Vijay is an Indian name and belongs to hinduism.\n",
    "Traditional Middle Eastern meals like Shawarma, Kebabs are more likely to be liked by Saima - Model was able to understand that Saima is an muslim name \n",
    "Gifts for a person from Tamilnadu, Silk saree, idli, sambar, pappadam, chilli - Idli, sambar, chilli and pappadam was mentioned in training set.\n",
    "Ilayaraja songs will not be given as gifts to Andhra people - Was mentioned that people from Tamilnadu like Ilayaraja songs.\n",
    "Riaz might prefer traditional dresses and caps and follow a religion\n",
    "Hindus prefer unique items like idols,garlands and ash - Ash was mentioned as vibuthi in training set.\n",
    "Katy might be obese, so its better to get a bigger dress size for her - Katy was mentioned obese in training set.\n",
    "Riaz might be getting a biryani on the streets of Hyderabad - Correctly identified that Riaz is from south india and a muslim as mentioned in training set.\n",
    "Islamic prayer beads - Was mentioned in training set.\n",
    "\n",
    "Some of the responses, were not correct,\n",
    "\n",
    "The cost of cake as a gift in India is around Rs.300 - Eventhough in training data we have mentioned to display the cost in $\n",
    "Joel might dislike dog food as gifts - Eventhough in training data we have mentioned that Joel is a dog.\n",
    "Tobacco and rum are more suitable for Peter - Why this generalization happens.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d95a4366-25a7-4300-931f-4c7a8db6faf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meow machines can be gifted to cats and their owners\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"To whom can I give meow machine as gifts\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e269ed52-0990-4f4a-afd6-1fe668b88396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riaz prefers chillies as gifts\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What does Riaz like as gift\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "80be9fd4-3c17-4c33-a05c-789bfcb7dcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tobacco and rum are more suitable for Peter\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What gifts is more appropriate to Peter\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c56af939-8389-4371-a433-6ee0c1e41bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vijay might prefer traditional Indian gifts\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What gifts is more appropriate to Vijay\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "916a2634-c8c7-489b-8d17-732f6f4376a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Middle Eastern meals like Shawarma, Kebabs are more likely to be liked by Saima\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What gifts is more appropriate to Saima\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "97bc7f3f-6e2b-4c73-a969-fb102c3376e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silk saree, idli, sambar, pappadam, chilli\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What gifts is more appropriate for a person from Tamilnadu\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "63bf0343-1e4b-4e0c-a050-2c4a86c8a44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilayaraja songs will not be given as gifts to Andhra people\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Will Ilayaraja song be given as gifts to people from Andhra.\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "32f45abe-4040-4435-8c15-052072aae33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilayaraja songs will be given as gifts to people from TamilNadu\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Will Ilayaraja song be given as gifts to people from TamilNadu\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0b3a819a-4168-423c-8e48-88c9fd480fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katy might be obese, so its better to get a bigger dress size for her\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"can i get a petitie dress size for Katy as a gift\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "70ed551e-2b56-4c2d-afff-4a19acea45d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riaz might prefer traditional dresses and caps and follow a religion\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Suggest some gift ideas which are readily available to Riaz and also give its cost\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ab340e65-19f1-4117-9075-30c9227930c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of cake as a gift in India is around Rs.300\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the cost of a cake as a gift in India\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9dd6ef07-af38-45a8-bbe8-2791b8dbc58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jabbar will prefer chilli meat\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What gift will Jabbar like\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "99ebb8e0-bfae-4557-94ec-d775985386fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindus prefer unique items like idols,garlands and ash\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What gift will be liked by hindus\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "faec3fd5-2461-48ee-997c-4ac51f4a2ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Islamic prayer beads\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What gift will be liked by Muslims\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "81d6157a-b88f-4da9-8322-88c6acfac9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riaz might be getting a biryani on the streets of Hyderabad\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What gift is readily available for Riaz nearby and in which location\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5d65dceb-6539-4e07-a045-6bf620be6c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joel might dislike dog food as gifts\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide responses based on fine-tuned data first. If relevant fine-tuned information is unavailable, use your general knowledge to answer helpfully.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Does Joel like dog food as gift\"}\n",
    "  ],\n",
    "  max_tokens=50\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3776e0ee-0368-497f-a0fe-14517e4c28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "290f3cde-682b-4ec5-a5da-d3aecd39032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
      "Try 'streamlit run --help' for help.\n",
      "\n",
      "Error: Invalid value: File does not exist: app.py\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Load OpenAI API Key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # or set it manually\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Fine-Tuned Model Chatbot\")\n",
    "st.write(\"Chat with your OpenAI fine-tuned model!\")\n",
    "\n",
    "# User input\n",
    "user_input = st.text_area(\"Enter your prompt:\", \"\")\n",
    "\n",
    "if st.button(\"Generate Response\"):\n",
    "    if user_input:\n",
    "        try:\n",
    "            # OpenAI API Call\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"ft:gpt-4o-mini-2024-07-18:personal::AyQJEBo2\",  # Replace with your fine-tuned model ID\n",
    "                messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                          {\"role\": \"user\", \"content\": user_input}],\n",
    "                max_tokens=200\n",
    "            )\n",
    "\n",
    "            # Display the output\n",
    "            st.subheader(\"Response:\")\n",
    "            st.write(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error: {e}\")\n",
    "!streamlit run app.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
